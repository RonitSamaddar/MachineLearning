{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.datasets import mnist#download mnist data and split into train and test sets\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=10000, random_state=42)","execution_count":3,"outputs":[{"output_type":"stream","text":"Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Seeing dimensions of the different sets\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":4,"outputs":[{"output_type":"stream","text":"(50000, 28, 28)\n(50000,)\n(10000, 28, 28)\n(10000,)\n(10000, 28, 28)\n(10000,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Seeing example of random images\nimage_no=5\nimg=X_train[image_no]\nplt.imshow(img)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7fb1af883450>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_X(X):\n    X_norm=X/255\n    return X_norm","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reshape_X(X):\n    X_reshaped=X.reshape(X.shape[0],28,28,1)\n    return X_reshaped","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##BUILDING THE MODEL\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten#create model\n\nmodel = Sequential()#add model layers\n\nmodel.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":9,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 24, 24, 32)        18464     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 18432)             0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                184330    \n=================================================================\nTotal params: 203,434\nTrainable params: 203,434\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pre processing the data\nX_train=reshape_X(normalize_X(X_train))\nX_val=reshape_X(normalize_X(X_val))\nX_test=reshape_X(normalize_X(X_test))\ny_train=to_categorical(y_train)\ny_val=to_categorical(y_val)\ny_test=to_categorical(y_test)\n","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train the model\nmodel.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)","execution_count":12,"outputs":[{"output_type":"stream","text":"Train on 50000 samples, validate on 10000 samples\nEpoch 1/10\n50000/50000 [==============================] - 11s 228us/step - loss: 0.1373 - accuracy: 0.9594 - val_loss: 0.0602 - val_accuracy: 0.9806\nEpoch 2/10\n50000/50000 [==============================] - 7s 142us/step - loss: 0.0533 - accuracy: 0.9832 - val_loss: 0.0526 - val_accuracy: 0.9845\nEpoch 3/10\n50000/50000 [==============================] - 7s 138us/step - loss: 0.0347 - accuracy: 0.9888 - val_loss: 0.0504 - val_accuracy: 0.9849\nEpoch 4/10\n50000/50000 [==============================] - 7s 142us/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0628 - val_accuracy: 0.9838\nEpoch 5/10\n50000/50000 [==============================] - 7s 148us/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0572 - val_accuracy: 0.9867\nEpoch 6/10\n50000/50000 [==============================] - 7s 136us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0628 - val_accuracy: 0.9862\nEpoch 7/10\n50000/50000 [==============================] - 7s 140us/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.0653 - val_accuracy: 0.9860\nEpoch 8/10\n50000/50000 [==============================] - 7s 146us/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.0735 - val_accuracy: 0.9858\nEpoch 9/10\n50000/50000 [==============================] - 8s 154us/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0930 - val_accuracy: 0.9846\nEpoch 10/10\n50000/50000 [==============================] - 7s 139us/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0849 - val_accuracy: 0.9852\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fb1acdc2290>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.evaluate(X_train,y_train)\n#print(result)\nprint(\"Training accuracy = \"+str(result[1]*100))\nresult = model.evaluate(X_val,y_val)\n#print(result)\nprint(\"Validation accuracy = \"+str(result[1]*100))\n#result = model.evaluate(X_test,y_test)\n#print(result)\n#print(\"Test accuracy = \"+str(result[1]*100))","execution_count":13,"outputs":[{"output_type":"stream","text":"50000/50000 [==============================] - 3s 69us/step\nTraining accuracy = 99.86799955368042\n10000/10000 [==============================] - 1s 90us/step\nValidation accuracy = 98.51999878883362\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}